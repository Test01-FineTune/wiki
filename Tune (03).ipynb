{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d6529f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9186546e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 1Ô∏è‚É£ Install Libraries (Same as before for consistency)\n",
    "!pip install accelerate==0.34.2 transformers==4.44.2 datasets==2.20.0 torch==2.3.1 -U\n",
    "\n",
    "# 2Ô∏è‚É£ Imports and Configuration\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification, # üö® NEW: For Classification Tasks\n",
    "    AutoTokenizer, \n",
    "    Trainer, \n",
    "    TrainingArguments,\n",
    "    DataCollatorWithPadding # üö® NEW: For efficient batch padding\n",
    ")\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "MODEL_NAME = \"distilbert-base-uncased\" # Fast, small model designed for classification\n",
    "\n",
    "print(\"‚è≥ Loading Model and Tokenizer...\")\n",
    "# We must tell the model how many classes (labels) it needs to predict. SST-2 has 2 (positive/negative).\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=2)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# DistilBERT uses a special [PAD] token, so we don't need the EOS hack from GPT-2.\n",
    "print(\"‚úÖ Model loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c5851c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 3Ô∏è‚É£ Load SST-2 Classification Dataset\n",
    "print(\"‚è≥ Loading SST-2 dataset...\")\n",
    "dataset = load_dataset(\"glue\", \"sst2\")\n",
    "\n",
    "# 4Ô∏è‚É£ Data Tokenization\n",
    "def tokenize_function(examples):\n",
    "    # This prepares the input sentence into tokens (input_ids)\n",
    "    # The [CLS] token is added at the start, [SEP] at the end, standard for BERT-models.\n",
    "    return tokenizer(examples[\"sentence\"], truncation=True)\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Remove the original text column and prepare the dataset for training\n",
    "tokenized_datasets = tokenized_datasets.remove_columns([\"sentence\", \"idx\"])\n",
    "\n",
    "# SST-2 labels are already 0 (negative) and 1 (positive), which is perfect.\n",
    "print(\"üìù Dataset pre-processing complete.\")\n",
    "\n",
    "# 5Ô∏è‚É£ Data Collator: Efficiently pad sequences to the longest in the batch\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "# 6Ô∏è‚É£ Define Evaluation Metrics\n",
    "# Classification requires metrics like Accuracy\n",
    "accuracy_metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    # The Trainer passes the model predictions here\n",
    "    predictions, labels = eval_pred\n",
    "    # The predictions are logits (raw scores), so we take the argmax to get the predicted class (0 or 1)\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy_metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "print(\"‚úÖ Evaluation metrics defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b241754e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Use a subset for a faster demonstration (for full training, remove the .select() line)\n",
    "train_subset = tokenized_datasets[\"train\"].select(range(5000)) \n",
    "eval_subset = tokenized_datasets[\"validation\"].select(range(500)) \n",
    "\n",
    "\n",
    "# 7Ô∏è‚É£ Define Training Arguments\n",
    "OUTPUT_DIR = \"./distilbert_sst2_results\"\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    num_train_epochs=3,          # Standard number of epochs for fine-tuning\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    learning_rate=2e-5,          # Standard learning rate for fine-tuning\n",
    "    logging_steps=100,\n",
    "    evaluation_strategy=\"epoch\", # Evaluate performance after each epoch\n",
    "    save_strategy=\"epoch\",       # Save a checkpoint after each epoch\n",
    "    load_best_model_as_init_model=True, # Load the best model found during training\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "# 8Ô∏è‚É£ Initialize and Train the Trainer\n",
    "print(\"üöÄ Initializing Trainer and starting fine-tuning...\")\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_subset,\n",
    "    eval_dataset=eval_subset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics # Pass our custom function\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "print(\"‚úÖ Fine-tuning complete!\")\n",
    "\n",
    "# 9Ô∏è‚É£ Test Inference\n",
    "from transformers import pipeline\n",
    "\n",
    "# Create a classification pipeline using the fine-tuned model\n",
    "classifier = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    device=0 if torch.cuda.is_available() else -1\n",
    ")\n",
    "\n",
    "test_sentences = [\n",
    "    \"This is an absolutely delightful film, highly recommended.\",\n",
    "    \"The plot was confusing and the characters were flat.\"\n",
    "]\n",
    "\n",
    "print(\"\\nüìù Testing Fine-Tuned Classifier:\")\n",
    "results = classifier(test_sentences)\n",
    "\n",
    "# The output label will be 'LABEL_0' (Negative) or 'LABEL_1' (Positive)\n",
    "# We can map these for clarity:\n",
    "label_map = {0: \"Negative\", 1: \"Positive\"}\n",
    "\n",
    "for sentence, result in zip(test_sentences, results):\n",
    "    label_id = int(result['label'].split('_')[-1])\n",
    "    sentiment = label_map[label_id]\n",
    "    score = result['score'] * 100\n",
    "    \n",
    "    print(f\"\\n- Text: '{sentence}'\")\n",
    "    print(f\"  Result: {sentiment} ({score:.2f}% confidence)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e877871",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc0a2e4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dead663f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0503b27e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc101f7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7be54f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7639f83a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c849e6d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db9b9f6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e186eeec",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0c37b5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d8405f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b1e44e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28ee5a5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce298e88",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafd6b78",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36c9efc",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb604a4d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2229f417",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b183cc14",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
